@inproceedings{mesoNet,
  title={Mesonet: a compact facial video forgery detection network},
  author={Afchar, Darius and Nozick, Vincent and Yamagishi, Junichi and Echizen, Isao},
  booktitle={2018 IEEE international workshop on information forensics and security (WIFS)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}

@INPROCEEDINGS{ManTraNet,
  author={Wu, Yue and AbdAlmageed, Wael and Natarajan, Premkumar},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features}, 
  year={2019},
  volume={},
  number={},
  pages={9535-9544},
  abstract={To fight against real-life image forgery, which commonly involves different types and combined manipulations, we propose a unified deep neural architecture called ManTraNet. Unlike many existing solutions, ManTra-Net is an end-to-end network that performs both detection and localization without extra preprocessing and postprocessing. ManTra-Net is a fully convolutional network and handles images of arbitrary sizes and many known forgery types such splicing, copy-move, removal, enhancement, and even unknown types. This paper has three salient contributions. We design a simple yet effective self-supervised learning task to learn robust image manipulation traces from classifying 385 image manipulation types. Further, we formulate the forgery localization problem as a local anomaly detection problem, design a Z-score feature to capture local anomaly, and propose a novel long short-term memory solution to assess local anomalies. Finally, we carefully conduct ablation experiments to systematically optimize the proposed network design. Our extensive experimental results demonstrate the generalizability, robustness and superiority of ManTra-Net, not only in single types of manipulations/forgeries, but also in their complicated combinations.},
  keywords={},
  doi={10.1109/CVPR.2019.00977},
  ISSN={2575-7075},
  month={June},}


  @inproceedings{rossler2019faceforensics++,
  title={Faceforensics++: Learning to detect manipulated facial images},
  author={Rossler, Andreas and Cozzolino, Davide and Verdoliva, Luisa and Riess, Christian and Thies, Justus and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1--11},
  year={2019}
}


@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@article{seneviratne2022dalle,
  title={DALLE-URBAN: Capturing the urban design expertise of large text to image transformers},
  author={Seneviratne, Sachith and Senanayake, Damith and Rasnayaka, Sanka and Vidanaarachchi, Rajith and Thompson, Jason},
  journal={arXiv preprint arXiv:2208.04139},
  year={2022}
}

@article{sha2022fake,
  title={DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models},
  author={Sha, Zeyang and Li, Zheng and Yu, Ning and Zhang, Yang},
  journal={arXiv preprint arXiv:2210.06998},
  year={2022}
}

@article{tolosana2020deepfakes,
  title={Deepfakes and beyond: A survey of face manipulation and fake detection},
  author={Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
  journal={Information Fusion},
  volume={64},
  pages={131--148},
  year={2020},
  publisher={Elsevier}
}


@conference{LatentDiffusionModels,
title = {High-Resolution Image Synthesis with Latent Diffusion Models},
author = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and BjÃ¶rn Ommer},
url = {https://github.com/CompVis/latent-diffusionhttps://arxiv.org/abs/2112.10752},
year  = {2022},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@article{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  journal={arXiv preprint arXiv:2302.05543},
  year={2023}
}

@inproceedings{nguyen2023new,
  title={A New Chapter for Medical Image Generation: The Stable Diffusion Method},
  author={Nguyen, Loc X and Aung, Pyae Sone and Le, Huy Q and Park, Seong-Bae and Hong, Choong Seon},
  booktitle={2023 International Conference on Information Networking (ICOIN)},
  pages={483--486},
  year={2023},
  organization={IEEE}
}

@article{hsu2020deep,
  title={Deep fake image detection based on pairwise learning},
  author={Hsu, Chih-Chung and Zhuang, Yi-Xiu and Lee, Chia-Yen},
  journal={Applied Sciences},
  volume={10},
  number={1},
  pages={370},
  year={2020},
  publisher={MDPI}
}

@inproceedings{marra2018detection,
  title={Detection of gan-generated fake images over social networks},
  author={Marra, Francesco and Gragnaniello, Diego and Cozzolino, Davide and Verdoliva, Luisa},
  booktitle={2018 IEEE conference on multimedia information processing and retrieval (MIPR)},
  pages={384--389},
  year={2018},
  organization={IEEE}
}

@article{hamid2023improvised,
  title={An improvised CNN model for fake image detection},
  author={Hamid, Yasir and Elyassami, Sanaa and Gulzar, Yonis and Balasaraswathi, Veeran Ranganathan and Habuza, Tetiana and Wani, Sharyar},
  journal={International Journal of Information Technology},
  volume={15},
  number={1},
  pages={5--15},
  year={2023},
  publisher={Springer}
}

@article{uloli2022survey,
  title={Survey of Fake Image Synthesis and its Detection},
  author={Uloli, Thiruvaazhi and Akash, RM Koushal and Keerthika, AG and Dhanwanth, KS},
  journal={Journal of Innovative Image Processing},
  volume={4},
  number={4},
  pages={278--298},
  year={2022}
}

@inproceedings{birunda2022fake,
  title={Fake Image Detection in Twitter using Flood Fill Algorithm and Deep Neural Networks},
  author={Birunda, S Selva and Nagaraj, P and Narayanan, S Krishna and Sudar, K Muthamil and Muneeswaran, V and Ramana, R},
  booktitle={2022 12th International Conference on Cloud Computing, Data Science \& Engineering (Confluence)},
  pages={285--290},
  year={2022},
  organization={IEEE}
}

@article{liao2021imperceptible,
  title={Imperceptible adversarial examples for fake image detection},
  author={Liao, Quanyu and Li, Yuezun and Wang, Xin and Kong, Bin and Zhu, Bin and Lyu, Siwei and Yin, Youbing and Song, Qi and Wu, Xi},
  journal={arXiv preprint arXiv:2106.01615},
  year={2021}
}
@article{nguyen2019use,
  title={Use of a capsule network to detect fake images and videos},
  author={Nguyen, Huy H and Yamagishi, Junichi and Echizen, Isao},
  journal={arXiv preprint arXiv:1910.12467},
  year={2019}
}



@misc{DeepFakegithub,
  title={Deepfake github},
  author={},
  howpublished={\url{https://github.com/deepfakes/faceswap}[Dostęp 11.05.2023]},
  month={1},
  day={11},
  year={2018}
}

@misc{thies2020face2face,
      title={Face2Face: Real-time Face Capture and Reenactment of RGB Videos}, 
      author={Justus Thies and Michael Zollhöfer and Marc Stamminger and Christian Theobalt and Matthias Nießner},
      year={2020},
      eprint={2007.14808},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{CLIP,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  journal      = {CoRR},
  volume       = {abs/2103.00020},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.00020},
  eprinttype    = {arXiv},
  eprint       = {2103.00020},
  timestamp    = {Thu, 04 Mar 2021 17:00:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2103-00020.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{howToSpotBalenciagaPope,
      title={How to Spot an AI-Generated Image Like the 'Balenciaga Pope'}, 
      author={Justus Thies and Michael Zollhöfer and Marc Stamminger and Christian Theobalt and Matthias Nießner},
      year={2023},

      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{creativity_of_text_to_image,
author = {Oppenlaender, Jonas},
title = {The Creativity of Text-to-Image Generation},
year = {2022},
isbn = {9781450399555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569219.3569352},
doi = {10.1145/3569219.3569352},
abstract = {Text-guided synthesis of images has made a giant leap towards becoming a mainstream phenomenon. With text-to-image generation systems, anybody can create digital images and artworks. This provokes the question of whether text-to-image generation is creative. This paper expounds on the nature of human creativity involved in text-to-image art (so-called “AI art”) with a specific focus on the practice of prompt engineering. The paper argues that the current product-centered view of creativity falls short in the context of text-to-image generation. A case exemplifying this shortcoming is provided and the importance of online communities for the creative ecosystem of text-to-image art is highlighted. The paper provides a high-level summary of this online ecosystem drawing on Rhodes’ conceptual four P model of creativity. Challenges for evaluating the creativity of text-to-image generation and opportunities for research on text-to-image generation in the field of Human-Computer Interaction (HCI) are discussed.},
booktitle = {Proceedings of the 25th International Academic Mindtrek Conference},
pages = {192–202},
numpages = {11},
keywords = {AI art, Midjourney, creativity, prompt engineering, generative art, text-guided image synthesis, text-to-image generation},
location = {Tampere, Finland},
series = {Academic Mindtrek '22}
}
